---
title: "Machine_Learning"
author: "Aaron Chandler"
date: "Sunday, September 27, 2015"
output: html_document
---
```{r echo=FALSE}
library(randomForest)
```


```{r echo=FALSE}
vars<-c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt", "gyros_belt_x", "gyros_belt_y", "gyros_belt_z", 
"accel_belt_x", "accel_belt_y", "accel_belt_z", "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", "pitch_arm", "yaw_arm", "total_accel_arm", "gyros_arm_x", "gyros_arm_y", "gyros_arm_z", "accel_arm_x", "accel_arm_y", "accel_arm_z", "magnet_arm_x", "magnet_arm_y", "magnet_arm_z", "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", "total_accel_dumbbell", 
"gyros_dumbbell_x", "gyros_dumbbell_y", "gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", 
"magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", "pitch_forearm", "yaw_forearm")
```

**Model Estimation**

This analysis predicts the "classe" variable from the Weight Lifting Exercises Dataset from the Human Activity Recognition project.

The final model is a random forest model that uses all variables in the dataset that were empirically collected through the motion sensors.  It is specified as:
 classe ~ ` r vars `
 
The reasoning for selecting these variables is that misperformance of exercise can lead to a wide variety of extraneous motion.  Specific misperformance more than likely yields specific extraneous motion.  Anticipating the wide variety of specific range for each of the 5 misperformances, as well as the efficient motion of the correct exercise performance would be difficult.  This difficulty of qualitatively assessing activity performance is described in the write-up accompanying the dataset.  Selecting all of the empirical variable provides the model with as much information as possible to identify the specific patterns associated with each classe.

```{r echo=FALSE}
#Data and pre-processing
dir<-getwd()
subdir<-"exercise"

##dir.create(file.path(dir,subdir),mode="0777")

##setwd(file.path(dir,subdir))

setInternet2(use = TRUE)

url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

##path <- file.path(getwd())
##download.file(url,path)

train<-read.csv(url,header=TRUE,sep=",",stringsAsFactors=FALSE)

train5<-train[vars]
train5$classe<-as.factor(train$classe)
```

```{r echo=FALSE}
modFit<-randomForest(classe~.,data=train5,mrty=6)
```

**Final Model**
The estimated model and in the in sample performance are below:

```{r}
modFit
```

**Cross-Validation**

K-Folds validation using 3 folds was used to cross validate the model.  The training dataset was randomly divided into 3 subsets.  Three additional model estimations were done excluding one of the three subsets to be used for testing.  The results for each validation are below.  The results are displayed in proportion tables.

``` {r echo=FALSE}
train5$sample<-sample(1:3,nrow(train5),replace=T)

valid1<-train5[train5$sample!=3,]
test1<-train5[train5$sample==3,]

modFit1<-modFit<-randomForest(classe~.,data=valid1,mrty=6)
pred1<-predict(modFit1,newdata=test1)

testtable1<-table(test1$classe,pred1)
prop1<-prop.table(testtable1,2)
mean(diag(prop.table(testtable1,2)))

valid2<-train5[train5$sample!=2,]
test2<-train5[train5$sample==2,]

modFit2<-randomForest(classe~.,data=valid2,mrty=6)
pred2<-predict(modFit2,newdata=test2)

testtable2<-table(test2$classe,pred2)
prop2<-prop.table(testtable2,2)
mean(diag(prop.table(testtable2,2)))

valid3<-train5[train5$sample!=1,]
test3<-train5[train5$sample==1,]

modFit3<-randomForest(classe~.,data=valid3,mrty=6)
pred3<-predict(modFit3,newdata=test3)

testtable3<-table(test3$classe,pred3)
prop3<-prop.table(testtable3,2)
mean(diag(prop.table(testtable3,2)))
```


**Cross Validation With Subset 1**
```{r}
prop1
```

The mean error rate for this subset is ` r 1-mean(diag(prop.table(testtable1,2)))`.

**Cross Validation With Subset 2**
```{r}
prop2
```

The mean error rate for this subset is ` r 1-mean(diag(prop.table(testtable2,2)))`.

**Cross Validation With Subset 3**
```{r}
prop3
```

The mean error rate for this subset is ` r 1-mean(diag(prop.table(testtable3,2))) `.


**Expected Error for Out-of-Sample Tests**
The expected error rate for this model is .711%, which is the mean of the error rates for each of the subset used for testing during the cross-validation.  The range for the error rate is expected to be between .57% and .8%, which are the upper and lower bounds of the error rates of the cross validation results.


**Prediction Using the Model**
The final task of this assignment was to predict the classifier of 20 test cases.  This model resulted in 100% accuracy for the test cases.


```{r}
url2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

final<-read.csv(url2,header=TRUE,stringsAsFactors=FALSE,sep=",")
final2<-final[vars]
final2$sample<-1

fpred<-predict(modFit,newdata=final2)

```

